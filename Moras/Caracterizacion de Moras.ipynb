{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.udem.edu.co/\"><img src=\"https://www.universidadesvirtuales.com.co/logos/original/logo-universidad-de-medellin.png\"></a>\n",
    "<h1>Reconocimiento de Patrones I</h1>\n",
    "<h3>2018-2</h3>\n",
    "<h2>Proyecto de Aula: Caracterización de moras</h2>\n",
    "</center>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estudiantes\n",
    "---\n",
    "\n",
    "Nombre: Ana María Sosa \n",
    "\n",
    "Identificación: 1017235052\n",
    "    \n",
    "Nombre: Melisa Morales Gómez\n",
    "    \n",
    "Identificación: 1035875351\n",
    "\n",
    "Nombre: Miguel Angel Mejia\n",
    "    \n",
    "Identificación: 1036646927\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción del proyecto\n",
    "---\n",
    "\n",
    "A través de tres clases de moras, las cuales se encuentran entre malas, buenas y regulares, se realizará a partir de las imágenes de estas moras una medición a través de regionprops lo que nos generará unas características entre las cuales se utilizarán el area, area convexa, excentricidad, etc. A partir de estos datos se se podrá resolver el problema, el cual será clasificar las moras en sus tres calidades.\n",
    "\n",
    "Este dataset consta de 240 imágenes, 80 de cada calidad. Fue tomado de un proyecto en el cuál se elaboró un sistema clasificador automático de moras dentro de esas tres clases (buenas, regulares y malas), desarrollado en el marco curso de procesamiento digital de imágenes de la Universidad de Antioquia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anasosa/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from skimage import data\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.color import rgb2gray\n",
    "from skimage import io\n",
    "from skimage import exposure\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.morphology import closing, square\n",
    "from skimage.segmentation import clear_border\n",
    "\n",
    "from sklearn import cross_validation\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Método Otsu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def otsu(mora):\n",
    "    p2, p98 = np.percentile(mora, (1, 98))\n",
    "    mora = exposure.rescale_intensity(mora, in_range=(p2, p98)) \n",
    "    \n",
    "    thresh1 = threshold_otsu(mora)\n",
    "    moraBinarizada = mora > thresh1\n",
    "\n",
    "    return moraBinarizada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lista de Moras Binarizadas y Etiquetadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se declara la lista para las imágenes y las etiquetas posibles\n",
    "moras = []\n",
    "\n",
    "def crear_moras(clase):\n",
    "    # Se recorre por la cantidad de imagenes que hay de cada clase que son 80\n",
    "    for j in range(1,81):\n",
    "        imagen = clase + \"/ImagenMora\" + str(j) +\".jpg\"\n",
    "        mora = Image.open(imagen)\n",
    "        mora = mora.convert('L')  \n",
    "        mora = np.asarray(mora,dtype=np.float32)\n",
    "         \n",
    "        tupla_mora = (otsu(mora), clase)\n",
    "        \n",
    "        moras.append(tupla_mora) \n",
    "        \n",
    "crear_moras('Moras buenas')\n",
    "crear_moras('Moras malas')\n",
    "crear_moras('Moras regulares')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(len(moras))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caracterización con RegionProps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caracterizando mora # 1 de la clase:  Moras buenas\n",
      "Caracterizando mora # 2 de la clase:  Moras buenas\n",
      "Caracterizando mora # 3 de la clase:  Moras malas\n",
      "Caracterizando mora # 4 de la clase:  Moras malas\n",
      "Caracterizando mora # 5 de la clase:  Moras regulares\n"
     ]
    }
   ],
   "source": [
    "X = [] \n",
    "y = []\n",
    "\n",
    "for i in range(len(moras)):\n",
    "    print('Caracterizando mora nuúmero', i+1, 'de la clase:', moras[i][1])\n",
    "    etiqueta = moras[i][1]\n",
    "    label_img = label(moras[i][0])\n",
    "    regions = regionprops(label_img)\n",
    "    \n",
    "    caracteristicas = [] \n",
    "    area = 0\n",
    "    numero_region = 0\n",
    "    cont = 0\n",
    "    for j in regions:\n",
    "        if j.area > area:\n",
    "            area = j.area                \n",
    "            numero_region = cont  \n",
    "            cont += 1\n",
    "\n",
    "    caracteristicas.append(area)      \n",
    "    caracteristicas.append(regions[numero_region].bbox_area)       \n",
    "    caracteristicas.append(regions[numero_region].convex_area)      \n",
    "    caracteristicas.append(regions[numero_region].eccentricity)        \n",
    "    caracteristicas.append(regions[numero_region].equivalent_diameter)     \n",
    "    caracteristicas.append(regions[numero_region].euler_number)\n",
    "    caracteristicas.append(regions[numero_region].extent)\n",
    "    caracteristicas.append(regions[numero_region].filled_area)   \n",
    "    caracteristicas.append(regions[numero_region].orientation)  \n",
    "    caracteristicas.append(regions[numero_region].perimeter)  \n",
    "    caracteristicas.append(regions[numero_region].solidity) \n",
    "\n",
    "    X.append(caracteristicas)\n",
    "\n",
    "    if etiqueta == 'Moras buenas':         \n",
    "        y.append(2)    \n",
    "    elif etiqueta == 'Moras regulares':  \n",
    "        y.append(1)\n",
    "    else:\n",
    "        y.append(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea la instancia de la clase para realizar cross validation usando Kfolds\n",
    "kf = cross_validation.KFold(len(moras), n_folds=10)\n",
    "\n",
    "# Se instancia la variable para almacenar los datos\n",
    "data = []\n",
    "\n",
    "# Se prueban diferentes valores de C y Gamma para maquinas de vectors de soporte(SVC)\n",
    "for c in (1,10,100):\n",
    "    row = [c]\n",
    "    rowError = [c]\n",
    "    for Gamma in (0.0001, 0.001, 0.01, 0.1):\n",
    "        X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.3)\n",
    "        clf = SVC(kernel='linear', C=c, gamma = Gamma, shrinking = True)    \n",
    "        clf.fit(X_train, y_train)           \n",
    "        scoresSVC = cross_validation.cross_val_score(clf, X_test, y_test, cv=10)\n",
    "        rowEf = str(\"%0.2f (+/- %0.2f)\" % (scoresSVC.mean(), scoresSVC.std() * 2))\n",
    "        rowErr = str(\"%0.2f (+/- %0.2f)\" % (1 - scoresSVC.mean(), scoresSVC.std() * 2))\n",
    "        row.append(rowEf)\n",
    "        row.append(rowErr)\n",
    "    data.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se realizan 10 iteraciones usando cross validation para el classificador de arboles de decición\n",
    "suma = 0\n",
    "for k, (train, test) in enumerate(kf):\n",
    "    X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.3)\n",
    "    clf = tree.DecisionTreeClassifier(max_leaf_nodes = 100)\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    suma += clf.score(X_test, y_test)\n",
    "scoresTree = cross_validation.cross_val_score(clf, X_test, y_test, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se corre  el clasificador \"Random forest\" con 10, 20, 30, 40 y 100 arboles con cross validation de 10 Kfolds\n",
    "forestData = []\n",
    "for N in (10, 20, 30, 40, 100):\n",
    "    forestRow = []\n",
    "    suma = 0\n",
    "    for k, (train, test) in enumerate(kf):\n",
    "        X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.3)\n",
    "        clf = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=0)  \n",
    "        clf.fit(X_train, y_train)\n",
    "        suma += clf.score(X_test, y_test)\n",
    "    scores = cross_validation.cross_val_score(clf, X_test, y_test, cv=10)    \n",
    "    forestData.append([N, (\"%0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2)),(\"%0.2f (+/- %0.2f)\" % (1 - scores.mean(), scores.std() * 2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Maquinas de vectores de soporte (SVC) Errores\")\n",
    "pd.DataFrame(data, columns=['C', '0.0001', 'error', '0.001', 'error', '0.01', 'error', '0.1', 'error' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Arbol de decición\")\n",
    "print((\"Eficiencia: %0.2f (+/- %0.2f)\" % (scoresTree.mean(), scoresTree.std() * 2)),(\" - Error: %0.2f (+/- %0.2f)\" % (1 - scoresTree.mean(), scoresTree.std() * 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Random forest\")\n",
    "pd.DataFrame(forestData, columns=['# Arboles', 'Eficiencia', 'Error'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Segun los resultados obtenidos de los tre modelos, el que presenta mejor eficiencia es \"Random forest\" con una configuración de 20 a 30 arboles, con un 70% de eficiencia en promedio y un intervalo de confianza relativamente bajo en comparación con los demas modelos (entre .28 y .32). realizando varias pruebas, los resultados apuntan a esta configuración, aunque en ocaciones con menos o más arboles puede tender a mejorar la eficiencia."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
