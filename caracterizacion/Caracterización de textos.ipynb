{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.udem.edu.co/\"><img src=\"img/Escudo.png\"></a>\n",
    "<h1>Reconocimiento de Patrones I</h1>\n",
    "<h3>2018-2</h3>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Los problemas del enfoque Naïve visto hasta ahora\n",
    "\n",
    "Cómo vimos en el laboratorio 1, la aproximación del modelo Naïve Bayes para clasificar documentos como positivos o negativos, no fue lo suficientemente robusta para alcanzar una medidas de desempeño aceptables. La razón de esto, por lo menos para el ejercicio propuesta en el laboratorio, es que el vocabulario usado en los artículos negativos \"pesó\" más que el usado en los artículos positivos y el modelo presentó un sesgo hacia los documentos de esa clase, perdiendo capacidad de discriminación.\n",
    "\n",
    "Hay que tener en cuenta que el enfoque del modelo es Naïve, como ya lo mencionamos en clases anteriores, por lo tanto, se requiere de estrategias de representación más robustas para mejorar el reconocimiento de patrones en los textos.\n",
    "\n",
    "En esta clase vamos a hablar de nuevos enfoques de clasificación y probaremos la clasificación con nuevas bases de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caracterización de textos más robusta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En clases anteriores hemos hablado del Part-of-Speech o etiquetado morfosintáctico y hemos mencionado algunas herramientas para realizarlo:\n",
    "\n",
    "(En línea)\n",
    "http://grupotnt.udea.edu.co/TNTagger\n",
    "\n",
    "(La que trabajaremos a partir de ahora)\n",
    "\n",
    "http://www.corpus.unam.mx/servicio-freeling/\n",
    "\n",
    "(De escritorio)\n",
    "\n",
    "TreeTagger\n",
    "\n",
    "Freeling\n",
    "\n",
    "NLTK (Natural Language Toolkit)\n",
    "\n",
    "Aunque esta última opción (NLTK) es una librería potente para procesamiento de lenguaje natural, y se debe explorar (consultar), para el español, Freeling es una excelente herramienta para POS, desambiguación de sentido y análisis sintáctico; por eso la usaremos en el curso. \n",
    "\n",
    "El etiquetado morfosintáctico juega un papel muy importante en el proceso de caracterización o representación de un texto como vector de características para fines de reconocimiento de patrones. por ejemplo: para el análisis de sentimientos, una de las clasificaciones que nos ocupa en el curso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acerca de Freeling\n",
    "\n",
    "http://nlp.lsi.upc.edu/freeling/index.php/node/1\n",
    "\n",
    "Es una herramienta open source para análisis de lenguaje. Permite realizar etiquetado morfosintáctico, análisis sintáctico, desambiguación de sentido, entre otros.\n",
    "\n",
    "Para los objetivos del curso nos interesa el POS, y para ello vamos a usar una API desarrollada en la UNAM, y que nos permitirá trabajar directamente desde el notebook con Python.\n",
    "\n",
    "http://www.corpus.unam.mx/servicio-freeling/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Cómo usar Freeling desde el notebook con la API de la UNAM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PI0MS00\n",
      "SP\n",
      "DA0MP0\n",
      "AQ0CP00\n",
      "NCMP000\n",
      "PR0CN00\n",
      "PP1CS00\n",
      "VAIP1S0\n",
      "VMP00SM\n",
      "Fc\n",
      "DA0MS0\n",
      "NCMS000\n",
      "RG\n",
      "DA00S0\n",
      "RG\n",
      "AQ0MS00\n",
      "Fc\n",
      "PP2CS00\n",
      "VMIP3P0\n",
      "VMN0000\n",
      "RG\n",
      "RG\n",
      "Fp\n",
      "DA0MS0\n",
      "NCMS000\n",
      "VSIP3S0\n",
      "RG\n",
      "AQ0MS00\n",
      "Fc\n",
      "DP3CSN\n",
      "NCFS000\n",
      "AQ0FS00\n",
      "CC\n",
      "DA0FS0\n",
      "NCFS000\n",
      "VSIP3S0\n",
      "DA0FS0\n",
      "AQ0CS00\n",
      "Fp\n",
      "AQ0MS00\n",
      "NCMS000\n",
      "VMIF1S0\n",
      "RG\n",
      "NCMP000\n",
      "Fc\n",
      "RG\n"
     ]
    }
   ],
   "source": [
    "#-*- coding: utf-8 -*-\n",
    "import requests\n",
    "\n",
    "#Archivo a ser enviado\n",
    "files = {'file': open('prueba.txt', 'r')}\n",
    "\n",
    "#Parámetros\n",
    "params = {'outf': 'tagged', 'format': 'json'}\n",
    "\n",
    "#Enviar petición\n",
    "url = \"http://www.corpus.unam.mx/servicio-freeling/analyze.php\"\n",
    "r = requests.post(url, files=files, params=params)\n",
    "#print (r)\n",
    "\n",
    "#Convertir de formato json\n",
    "obj = r.json()\n",
    "\n",
    "#pint(len(obj))    #obj es una lista de listas. Tiene tantos elementos (listas) como frases tenga el file\n",
    " \n",
    "#Ejemplo, obtener todos los lemas\n",
    "for sentence in obj:\n",
    "    #print (sentence)    #sentence es una lista de diccionarios. Tiente tantos elementos (diccionarios)\n",
    "                         #como palabras tiene la frase\n",
    "    for word in sentence:\n",
    "        #word es un diccionario con 4 claves: token, lemma, tag y prob(probabilidad de que el tag haya sido bien asignado)\n",
    "        #A través de esas cuatro claves se podrá acceder a la información que requerimos para\n",
    "        #Comenzar a construir el vector de características de un texto\n",
    "        print (word['tag'])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De los diccionarios (word) que se muestran al ejecutar la celda anterior hay varios aspectos para analizar.\n",
    "\n",
    "¿Qué es token?\n",
    "\n",
    "Es cada palabra que aparece en el texto.\n",
    "\n",
    "¿Qué es lemma?\n",
    "\n",
    "Es la palabra raíz del token.\n",
    "\n",
    "¿Qué es tag y cuáles hay?\n",
    "\n",
    "https://talp-upc.gitbooks.io/freeling-4-0-user-manual/content/tagsets/tagset-es.html\n",
    "\n",
    "¿Qué es prob?\n",
    "\n",
    "Es la probabilidad de que el tag asignado sea correcto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aspectos clásicos para la caracterización de textos para análisis de sentimientos\n",
    "\n",
    "(Consultar el texto Sentiment Analysis - Mining Opinions, Sentiments and Emotions. Bing Liu, 2015.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la literatura se resportan diferentes enfoques para abordar el problema de reconocimiento de patrones en textos, conocido como análisis de sentimientos. Uno de los enfoques más usados, especialmente para textos donde se plasman revisiones de productos o servicios, es la caracterización de los textos a partir de los adjetivos. Esto es, un texto se representa con dos características:\n",
    "\n",
    "X1: la frecuencia de aparición de adjetivos positivos (puede ser frecuencia relativa respecto al # de tokens del texto o frecuencia absoluta)\n",
    "\n",
    "X2: la frecuencia de aparición de adjetivos negativos (puede ser frecuencia relativa respecto al # de tokens del texto o frecuencia absoluta)\n",
    "\n",
    "Gracias al POS ya se pueden identificar de manera automática los adjetivos dentro del texto. Sin embargo, surgen una nueva pregunta.\n",
    "\n",
    "¿El POS nos dice si el adjetivo es positivo o negativo?\n",
    "\n",
    "La respuesta es, No. Para encontrar la \"carga de sentimiento\" o polaridad de los adjetivos (en general de cualquier palabra), una posible alternativa es usar lo que se conoce como bases de datos léxicas. En el curso vamos a trabajar con la base de datos conocida como MLSenticon (http://timm.ujaen.es/recursos/ml-senticon/).\n",
    "\n",
    "Sin embargo, existen otras bases de datos léxicas (disponibles para el inglés) muy conocidas como SentiWordNet, MPQA, entre otras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La negación\n",
    "\n",
    "Un aspecto fundamental cuando se trabaja en análisis de sentimientos es la negación. Como ya hemos mencionado en la introducción del curso, la identificación automática de las negaciones es fundamental para identificar la polaridad completa de una oración o de un texto, puesto que a pesar de encontrar una alta frecuencia de entradas positivas (i.e., adjetivos), si estas están negadas, entonces la polaridad del texto es negativa y no positiva.\n",
    "\n",
    "En el curso trabajaremos con un enfoque básico reportado en la literatura, que consiste en identificar la presencia de la negación dentro de una oración y ajustar la polaridad de la misma de acuerdo a la presencia o ausencia de la negación. Esto se traduce en una nueva característica:\n",
    "\n",
    "X3: 1 (Si hay presencia de negación en la oración) | 0 (Si no hay presencia de negación en la oración)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Veamos algunos ejemplos de textos positivos y negativos\n",
    "\n",
    "Los siguientes ejemplos son reales. Tomados de las calificaciones dejadas en Booking por usuarios del Hotel Dann Carlton en Medellín. (https://www.booking.com/hotel/co/dann-carlton-medellin.es.html?label=gen173nr-1DCAEoggJCAlhYSDNYBGgyiAEBmAEKwgEKd2luZG93cyAxMMgBDNgBA-gBAZICAXmoAgM;sid=05e2a52229dbab954a14b9838f09e4cb;dest_id=-592318;dest_type=city;dist=0;group_adults=2;hapos=1;hpos=1;room1=A%2CA;sb_price_type=total;srepoch=1535390967;srfid=88dea29671deb6c48a3cad6576fe653a3f08ccd9X1;srpvid=ff807afb0f3400e4;type=total;ucfs=1&#hotelTmpl)\n",
    "\n",
    "### Revisiones de productos o servicios\n",
    "\n",
    "### Positivos\n",
    "\n",
    "La habitación muy cómoda y grande, la comida deliciosa, el personal muy amable. (pos)\n",
    "\n",
    "Servicio y personal excelente. (pos)\n",
    "\n",
    "el servico del personal es excelente, los desayunos son magnificos aunque falta un poco mas de variedad, el valor de las comidas a la carta son un poco elevados pero de gran calidad. (pos)\n",
    "\n",
    "Es muy agradable en todos los aspectos. El servicio excelente (pos)\n",
    "\n",
    "El servicio es muy bueno, el personal siempre esta atento y es muy amable, la comida en los restaurantes es magnifica, recomiendo el restaurante el puerto (parrilla Argentina) realmente espectacular. (pos)\n",
    "\n",
    "La habitación es moderna y muy cómoda (pos)\n",
    "\n",
    "Camas muy comodas, habitaciones muy limpias, personal muy amable y servicial. (pos)\n",
    "\n",
    "Excelente ubicación, cuarto automatizado, manejas todo desde el control del Directv. La piscina es temperada lo que la hace utilizable en días no cálidos. Mis hijos disfrutaron mucho. (pos)\n",
    "\n",
    "El control remoto del tv es inteligente y te permite controlar iluminación y blackout.\n",
    "La cama lo mejor de lo mejor! (pos)\n",
    "\n",
    "La cama es muy cómoda. Buen tipo de colchón, ya que permite descansar en forma bastante cómoda. (pos)\n",
    "\n",
    "\n",
    "### Negativos\n",
    "\n",
    "Cenamos en el Restaurant \"Tony Roman\" goratorio de el hotel, pero nuestra experiance <b>no</b> fue tan placentera. La comida es pasable, pero la persona que estaba cantando era extremadamente mala entonada! la musica estaba a tan alto volumen que no podiamos hablar sin gritar. Arruino nuestra cena con eso. (neg)\n",
    "\n",
    "El turco no representa un hotel 5 estrellas. (neg)\n",
    "\n",
    "Hotel muy grande, algún evento quizás te puede resultar molesto. Desayuno bueno <b>pero</b> podría estar mejor. (neg)\n",
    "\n",
    "El seguro hotelero no está incluido ni descrito en el precio y aumentó un 20% la estadía con mi familia. Eso debería mejorarlo Booking. No pude usar el televisor con Internet para ver Netflix porque solo te dejan el control del Directv. (neg)\n",
    "\n",
    "me parecieron exagerados los precios de la fuente de soda de la piscina.\n",
    "no me pareció agradable los cargos extras de sorpresa q me cobraron por mi hijo de 13años. no decia nada booking. (neg) <b>Este está marcado como positivo en Booking, qué opina?</b>\n",
    "\n",
    "Los pequeño detalles como un switch de la mesa de noche estaba dañado y otras cosas estaban algo viejas. (neg)\n",
    "\n",
    "El servicio de atención en la piscina es un desastre! La persona que me atendió fue muy deshonesto con la cuenta, pero por la prisa al aeropuerto no pude reclamar en el lugar! (neg)\n",
    "\n",
    "Básicamente no entiendo para que booking da la opción de escribir solicitudes especiales si el hotel no las tiene en cuenta. Escribí que quería una habitación con buena ubicación y buena vista. Y me ubicaron en la habitación más oscura del hotel en el tercer piso, la sensación de oscuridad y vista me hacía sentir que estuviera en el primer piso del hotel. Además que al lado de mi habitación (yo estaba en la 301) estaban realizando unos trabajos y escuché desde las 6;30 de la mañana martillazos. Lo cual no entiendo cómo hacen ruido en trabajos Locativos desde tan temprano. No pude descansar, me tocó levantarme temprano. (neg)\n",
    "\n",
    "la comida no es muy buena. (neg)\n",
    "\n",
    "El baño, específicamente el inodoro, es malo, uno tiene que que halar varias veces. La comida del restaurante argentino mala. El servicio en el comedor a diferencia de la vez pasada ha decaído. (neg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notar la importancia de las negaciones en algunos de los textos negativos.\n",
    "Es por la polaridad y la negacion\n",
    "\n",
    "#### Hay que ser concientes de las limitaciones del recurso léxico ML Senticon.\n",
    "\n",
    "#### Notar que se pueden crear múltiples representaciones de los textos basadas en POS, no solo de un único token sino usando características poliléxicas (i.e., V+Art+Nombre, Adv+Adj, Nombre+Adj, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio de Clase\n",
    "\n",
    "1. Con los 20 textos de revisiones de productos o servicios del Hotel presentados en la celda anterior, cree dos directorios, uno para los positivos y otro para los negativos, donde cada texto esté guardado en un archivo independiente con el nombre text_pos_1.txt o text_neg_1.txt según sea positivo o negativo y variando el identicador para cada archivo desde 1 hasta 10 para cada clase (pos o neg).\n",
    "\n",
    "2. Construya un scritp en una celda de código para realizar el etiquetado morfosintáctico de todos los textos de la base de datos construída.\n",
    "\n",
    "3. Usando el recurso léxico ML Senticon construya la representación vectorial de cada texto de la siguiente manera:\n",
    "\n",
    "Cada texto va a estar represetado por dos características.\n",
    "\n",
    "X1: carga positiva de los adjetivos encontrados en el texto\n",
    "\n",
    "X2: carga negativa de los adjetivos encontrados en el texto\n",
    "\n",
    "Tenga en cuenta que primero se deben identificar los adjetivos, luego tomar la carga que este tenga en ML Senticon, e ir sumando las cargas. Si el adjetivo no se encuentra en ML Senticon asignarle una carga de cero.\n",
    "\n",
    "<b>Muy importante, la negación</b>. Si en una oración hay presencia de negación (no, pero, aunque), se debe invertir la polaridad de los adjetivos que se encuentren dentro de dicha oración.\n",
    "\n",
    "No olvide tener en cuenta la etiqueta (pos o neg) de cara texto.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.438, 0]\n",
      "[0.75, 0]\n",
      "[1.088, 0]\n",
      "[1.5, 0]\n",
      "[1.904, 0]\n",
      "[0.328, 0]\n",
      "[1.532, 0]\n",
      "[1.125, 0]\n",
      "[1.354, 0]\n",
      "[0.5, 0]\n"
     ]
    }
   ],
   "source": [
    "# Construya un script en una celda de código para realizar el etiquetado \n",
    "# morfosintáctico de todos los textos de la base de datos construída.\n",
    "#-*- coding: utf-8 -*-\n",
    "import requests\n",
    "\n",
    "sentimientos = open('MLSenticon.txt', 'r')\n",
    "\n",
    "MLSenticonDic = { }\n",
    "for word in sentimientos:\n",
    "    palabra = word.split('\\t')[0]\n",
    "    valor = float(word.split('\\t')[1][:-1])\n",
    "    MLSenticonDic[palabra] = valor\n",
    "\n",
    "\n",
    "    \n",
    "for i in range(10):\n",
    "    vectorCaracteristicas = [0,0]\n",
    "    #Archivo a ser enviado\n",
    "    files = {\n",
    "        'file': open('positivos/text_pos_'+ str(i+1) +'.txt', 'r')\n",
    "    }\n",
    "\n",
    "   # print(files)\n",
    "    #Parámetros\n",
    "    params = {'outf': 'tagged', 'format': 'json'}\n",
    "\n",
    "    #Enviar petición\n",
    "    url = \"http://www.corpus.unam.mx/servicio-freeling/analyze.php\"\n",
    "    r = requests.post(url, files=files, params=params)\n",
    "   # print (r.text)\n",
    "\n",
    "    #Convertir de formato json\n",
    "    obj = r.json()\n",
    "\n",
    "    #pint(len(obj))    #obj es una lista de listas. Tiene tantos elementos (listas) como frases tenga el file\n",
    "\n",
    "    #Ejemplo, obtener todos los lemas\n",
    "    for sentence in obj:\n",
    "        #print (sentence)    #sentence es una lista de diccionarios. Tiente tantos elementos (diccionarios)\n",
    "                             #como palabras tiene la frase\n",
    "        for word in sentence:\n",
    "            #word es un diccionario con 4 claves: token, lemma, tag y prob(probabilidad de que el tag haya sido bien asignado)\n",
    "            #A través de esas cuatro claves se podrá acceder a la información que requerimos para\n",
    "            #Comenzar a construir el vector de características de un texto\n",
    "            if (word['tag'][0] == 'A'):\n",
    "                lema = word['lemma']\n",
    "               # print(lema)\n",
    "                \n",
    "                try: \n",
    "                    valor = MLSenticonDic[lema]\n",
    "                except:\n",
    "                    valor = 0\n",
    "                \n",
    "                if (valor > 0):\n",
    "                    vectorCaracteristicas[0] += valor\n",
    "                else:\n",
    "                    vectorCaracteristicas[1] += valor\n",
    "                       \n",
    "    print(vectorCaracteristicas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "placentero 0.875\n",
      "pasable 0.542\n",
      "malo -0.0\n",
      "grande 0.292\n",
      "molesto -0.538\n",
      "bueno 0.5\n",
      "mejor 0.375\n",
      "agradable 0.75\n",
      "extra 0.25\n",
      "positivo 0.594\n",
      "deshonesto -0.5\n",
      "especial 0.411\n",
      "bueno 0.5\n",
      "bueno 0.5\n",
      "oscuro -0.575\n",
      "bueno 0.5\n",
      "malo -0.0\n",
      "malo -0.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    vectorCaracteristicas = [0,0]\n",
    "    #Archivo a ser enviado\n",
    "    files = {\n",
    "        'file': open('negativos/text_neg_'+ str(i+1) +'.txt', 'r')\n",
    "    }\n",
    "\n",
    "   # print(files)\n",
    "    #Parámetros\n",
    "    params = {'outf': 'tagged', 'format': 'json'}\n",
    "\n",
    "    #Enviar petición\n",
    "    url = \"http://www.corpus.unam.mx/servicio-freeling/analyze.php\"\n",
    "    r = requests.post(url, files=files, params=params)\n",
    "   # print (r.text)\n",
    "\n",
    "    #Convertir de formato json\n",
    "    obj = r.json()\n",
    "\n",
    "    #pint(len(obj))    #obj es una lista de listas. Tiene tantos elementos (listas) como frases tenga el file\n",
    "\n",
    "    #Ejemplo, obtener todos los lemas\n",
    "    for sentence in obj:\n",
    "        #print (sentence)    #sentence es una lista de diccionarios. Tiente tantos elementos (diccionarios)\n",
    "                             #como palabras tiene la frase\n",
    "        for word in sentence:\n",
    "            #word es un diccionario con 4 claves: token, lemma, tag y prob(probabilidad de que el tag haya sido bien asignado)\n",
    "            #A través de esas cuatro claves se podrá acceder a la información que requerimos para\n",
    "            #Comenzar a construir el vector de características de un texto\n",
    "            if (word['tag'][0] == 'A'):\n",
    "                lema = word['lemma']\n",
    "               # print(lema)\n",
    "                \n",
    "                try: \n",
    "                    valor = MLSenticonDic[lema]\n",
    "                    print(lema, valor)\n",
    "                except:\n",
    "                    valor = 0\n",
    "                \n",
    "                if (valor > 0):\n",
    "                    vectorCaracteristicas[0] += valor\n",
    "                else:\n",
    "                    vectorCaracteristicas[1] += valor\n",
    "                       \n",
    "    #print(vectorCaracteristicas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recordar los modelos Logistic Regression y KNN para clasificar los textos del ejercicio y comparar con lo que haría Naïve Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otras representaciones y otros tipos de clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el área de la recuperación de información (IR), se trabaja una clasificación no supervisada de los textos. Allí hay varias técnicas de representación y modelos que intentan resolver el problema de agrupar los textos por temas. Es importante conocer de qué se tratan estas técnicas que trabajan bajo un enfoque distinto al del POS para representar los textos.\n",
    "\n",
    "<b>Representación Term-Document Matrix (TDM) (Matriz de términos en documentos):</b>\n",
    "\n",
    "Es una matriz en la que cada fila representa una palabra del vocabulario y cada columna representa un documento de la colección de documentos sobre la cuál se trabaja. Esta matriz fue definida por primera en la presentación del modelo $\\textit{vector space model}$ (Salton, 1971).\n",
    "\n",
    "Veamos un ejemplo a partir de una pequeña porción de la matriz de términos en documentos para cuatro palabras en cuatro novelas de Shakespeare.\n",
    "\n",
    "<img src=\"img/TDM_img_1.png\">\n",
    "\n",
    "Las marcas rojas nos dicen que cada documento se puede ver como un vector columna que está definido por la frecuencia de aparición de cada palabra de un vocabulario dentro del documento.\n",
    "\n",
    "Para ver una representación gráfica de los documentos (novelas) vamos a tener en cuenta solo 2 dimensiones (battle y fool).\n",
    "\n",
    "<img src=\"img/TDM_img_2.png\">\n",
    "\n",
    "En recuperación de información la tarea consiste en encontrar un documento $d$ dentro de una colección de documentos $D$, de tal manera que se satisfaga una consulta $q$. De esta manera, $q$ debe ser representada como un vector (documento) y posteriormente comparada con los vectores que representan los documentos $D$ para recuperar el documento $d$ (pueden ser varios documentos recuperados) más simular a $q$. Más adelante veremos cómo se puede medir la simulitud entre estos vectores que represetan los documentos.\n",
    "\n",
    "La idea que hay detrás de la representación TDM es que dos documentos similares tiene palabras similares y por lo tanto, tendrán representaciones similares como vectores columna.\n",
    "\n",
    "<b>Representación Term-Term Matrix (Matriz de términos en contextos):</b>\n",
    "\n",
    "Existe una representación muy usada actualmente, conocida como embedding y que surge a partir de la matriz de terminos en contextos. En esta representación se ve cada palabra como un vector y es útil para comparar la simulitud semántica entre dos palabras y por lo tanto entre documentos que contengan esas palabras, de allí el nombre de representación en vectores semánticos.\n",
    "\n",
    "En esta representación cada fila corresponde al vector que representa a una palabra y en las columnas se encuentran también palabras, que definen un contexto alrededor de dicha palabra en un corpus específico. Esto es, la matriz Term-Term Matrix, de dimensión |V|x|V|, tiene en cada una de sus entradas o posiciones la frecuencia de coocurrencia de la palabra de la fila con el contexto definido alrededor de la palabra de la columna. El contexto se suele definir con una ventana de entre 1 y 8 caracteres a izquierda y derecha de la palabra. Mientras más pequeña la ventana del contexto más se acerca el vector a una representación sintáctica. Por su parte, si la ventana es más amplia se acerca a una representación semántica. Veamos un ejemplo para comprender este concepto:\n",
    "\n",
    "<img src=\"img/TTM_img_1.png\">\n",
    "\n",
    "Contexto definido como una ventana de 7 tokens a izquierda y derecha.\n",
    "\n",
    "<img src=\"img/TTM_img_2.png\">\n",
    "\n",
    "Porción de Term-Term Matrix. Notar que esta matriz es una matriz sparse. \n",
    "\n",
    "Veamos la representación visual de los vectores semánticos de las palabras digital & information.\n",
    "\n",
    "<img src=\"img/TTM_img_3.png\">\n",
    "\n",
    "Esta gráfica se interpreta así:\n",
    "\n",
    "la palabra digital coocurre una vez con la palabra result en un contexto definido a partir de una ventana de 7 caracteres a izquierda y derecha. De igual manera coocurre una vez con la palabra data.\n",
    "\n",
    "Por su parte, la palabra information, coocurre 4 veces con la palabra result y 6 veces con la palabra data dentro de los contextos definidos bajo la misma ventaja.\n",
    "\n",
    "Notar que el vector que representa una palabra es del tamaño del vocabulario (|V|), regularmente entre 10.000 y 50.000 entradas, esto si se usan las palabras más frecuentes en un corpus de entrenamiento. Por esta razón es que la matriz de términos en contextos es sparse y se requiere de algoritmos eficientes para trabajar con ella.\n",
    "\n",
    "Si bien la matriz de términos en contextos nos da una medida de asociación entre dos palabras, está basada únicamente en una frecuencia de coocurrencia y esto en muchos contextos no es suficiente. Por tal razón, existen otras medidas más robustas como Positive Pointwise Mutual Information (PPMI) o TF-IDF.\n",
    "\n",
    "<b>Term Frequency - Inverse Term Frequency Scheme (TF-IDF)</b>\n",
    "\n",
    "Esta medida está definida como el producto de dos factores:\n",
    "\n",
    "TF: la frecuencia de una palabra en un documento. (se suele usar el logarítmo de esa frecuencia)\n",
    "IDF: el cociente entre el # total de documentos ($N$) y el número de documentos en los cuáles aparece la palabra ($df_i$).\n",
    "\n",
    "$$idf_i = log(\\frac{N}{df_i})$$\n",
    "\n",
    "Al combinar $TF$ con $IDF$ surge el esquema de pesado $tf-idf$ para una palabra $w_i$ en un documento $j$.\n",
    "\n",
    "$$w_{ij} = tf_{ij}idf_i  $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Para medir similaridad: el coseno\n",
    "\n",
    "Debido a que las palabras se pueden representar como vectores semánticos, se puede medir similaridad entre esas palabras si se mide la simularidad entre los vectores que las representan. La medida más usada en el procesamiento de lenguaje natural para medir esa similaridad es el coseno. A partir de la definición del producto interno visto en álgebra lineal:\n",
    "\n",
    "<img src=\"img/cos.png\">\n",
    "\n",
    "Por lo tanto,\n",
    "\n",
    "<img src=\"img/cos_2.png\">\n",
    "\n",
    "Considere el siguiente ejercicio:\n",
    "\n",
    "A partir de la medida de similitud del coseno determine cual de las dos palabras, apricot o digital, está más cerca semánticamente de la palabra information. Tenga en cuenta la representación de la siguiente tabla.\n",
    "\n",
    "<img src=\"img/ejemplo_cos.png\"><br><!-- <img src=\"ejemplo_cos_result.png\"> <br><img src=\"ejemplo_cos_result_graph.png\">-->\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Referencias\n",
    "\n",
    "Jurafsky, D., & Martin, J. H. (2014). Speech and language processing (Vol. 3). London: Pearson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
